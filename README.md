# ğŸ“„ Scraper DOGV (Diari Oficial de la Generalitat Valenciana)

Este proyecto es un **scraper automatizado con Selenium** que permite descargar boletines oficiales del **DOGV** en los idiomas *valenciano* y *castellano*, guardar su contenido en texto y HTML y generar un Ã­ndice JSON con los metadatos recopilados.

El script realiza automÃ¡ticamente una bÃºsqueda avanzada en la web del DOGV dentro de un rango de fechas, recorre miles de resultados, abre cada boletÃ­n en una nueva pestaÃ±a, extrae la informaciÃ³n estructurada y genera los archivos correspondientes.


## ğŸš€ CaracterÃ­sticas principales

- Uso de **Selenium en modo headless** para automatizar la navegaciÃ³n.
- BÃºsqueda avanzada automÃ¡tica en el portal oficial del DOGV.
- Scraping de:
  - TÃ­tulo del boletÃ­n.
  - Metadata del documento (mediante `<dl>`, `<dt>`, `<dd>`).
  - Contenido textual principal.
- Descarga del boletÃ­n tanto en **valenciano (`va`)** como en **castellano (`es`)**.
- Guardado de:
  - Documento completo en **HTML**.
  - Contenido limpio en **TXT**.
  - Ãndice global en **JSON**.
- Control robusto mediante:
  - `WebDriverWait`
  - Manejo de iframes
  - Reintentos en caso de error de carga.


## ğŸ“ Estructura de archivos generados

El script se ejecuta en base a la siguiente estructura:

```
dogv/
â”‚
â”œâ”€â”€ html/
â”‚ â””â”€â”€ <fechas>/
â”‚ â”œâ”€â”€ va/
â”‚ â”‚ â””â”€â”€ <ID>.html
â”‚ â””â”€â”€ es/
â”‚ â””â”€â”€ <ID>.html
â”‚
â”œâ”€â”€ plain/
â”‚ â””â”€â”€ <fechas>/
â”‚ â”œâ”€â”€ va/
â”‚ â”‚ â””â”€â”€ <ID>.txt
â”‚ â””â”€â”€ es/
â”‚ â””â”€â”€ <ID>.txt
â”‚
â””â”€â”€ index-<fechas>.json
```

Las carpetas `<fechas>` hacen referencia a la fecha que estamos descargando. Cada archivo `<ID>` corresponde al identificador obtenido desde la URL del boletÃ­n.

## ğŸ§° Requisitos

### ğŸ“¦ Dependencias de Python

- `selenium`
- `json`
- `time`
- `os`

### ğŸ–¥ï¸ Requisitos del sistema

- Chrome instalado.
- ChromeDriver compatible con tu versiÃ³n de Chrome.
- Sistema operativo Windows/Linux/macOS.

## â–¶ï¸ EjecuciÃ³n del script

Ejecuta:

```
python scraper_dogv.py
```

El flujo principal de ejecuciÃ³n:

1. Inicializa dos instancias de Chrome en modo headless (una para va y otra para es).
2. Accede al portal del DOGV y abre la bÃºsqueda avanzada dentro del iframe.
3. Inserta el rango de fechas configurado en el script.
4. Itera por las pÃ¡ginas de resultados (hasta el lÃ­mite fijado en el bucle).
5. Para cada boletÃ­n:
    - Abre la tarjeta en una nueva pestaÃ±a.
    - Extrae tÃ­tulo, metadatos (`<dl>`) y contenido.
    - Guarda HTML y TXT en las carpetas correspondientes.
    - Registra la entrada en el Ã­ndice JSON.
6. Repite el proceso con la versiÃ³n en castellano (`/es/`).

## ğŸ§  Funcionamiento interno
### InicializaciÃ³n del navegador

- Se crean chrome_options con argumentos:
    - `--headless`
    - `--no-sandbox`
    - `--disable-notifications`
    - `--incognito`
    - `--window-size=1920,1080`
- Se desactivan indicadores de automatizaciÃ³n mediante:
    - `excludeSwitches: ["enable-automation"]`
    - `useAutomationExtension: False`
- Se inicializan dos `webdriver.Chrome(options=chrome_options)` (uno para cada idioma).

### NavegaciÃ³n y manejo de iframes

- El portal del DOGV carga el buscador dentro de un `iframe`: el script siempre hace `switch_to.frame(...)` antes de interactuar.
- Se usan `time.sleep()` y `WebDriverWait` para sincronizar.
- Para avanzar pÃ¡ginas en los resultados se utiliza el selector `a[aria-label="Next"]` con reintentos si falla.

### ExtracciÃ³n de datos

- **TÃ­tulo**: se busca el primer `<h2>` visible.
- **Metadatos**: se extraen desde la lista de definiciÃ³n (`<dl>`) emparejando `<dt>` y `<dd>`.
- **Contenido**: toma el texto del contenedor `div.col-sm-12.col-lg-7.scroll-h-container`.
- **Guardado**:
    - HTML: se guarda `driver.page_source en dogv/html/<fechas>/<lang>/<ID>.html`.
    - Texto: se guarda el `content` en `dogv/plain/<fechas>/<lang>/<ID>.txt`.
- **Ãndice JSON**: se va aÃ±adiendo un diccionario por documento y se escribe en `dogv/index-<fechas>.json`.

### 4. GeneraciÃ³n del Ã­ndice JSON

Cada boletÃ­n se aÃ±ade como un objeto:

```
{
  "source": "https://dogv.gva.es/...",
  "title": "TÃ­tulo",
  "metadata": { ... },
  "language": <lang>,
  "path2html": "/html/<fechas>/<lang>/<ID>.html",
  "path2txt": "/plain/<fechas>/<lang>/<ID>.txt"
}
```

## Funding

This resource is funded by the *Ministerio para la TransformaciÃ³n Digital y de la FunciÃ³n PÃºblica* â€” Funded by **EU â€“ NextGenerationEU**, within the framework of the project *Desarrollo de Modelos ALIA*.

## Acknowledgments

We extend our gratitude to all individuals and institutions that contributed to the development of this resource.

Special thanks to:

- [Data providers]  
- [Technological support providers]

We also acknowledge the financial, scientific, and technical contributions of the *Ministerio para la TransformaciÃ³n Digital y de la FunciÃ³n PÃºblica â€“ Funded by EU â€“ NextGenerationEU* within the framework of the *Desarrollo de Modelos ALIA* project.

## Reference

Please cite this dataset using the following BibTeX entry:

```bibtex
@misc{uji_parallel_va_en_2025,
  author       = {Espinosa Zaragoza, Sergio and Sep{\'u}lveda Torres, Robiert and Mu{\~n}oz Guillena, Rafael and Consuegra-Ayala, Juan Pablo}, <-- ACTUALIZAR
  title        = {ALIA_DOGV Scraper},
  year         = {2025},
  institution  = {Language and Information Systems Group (GPLSI) and Centro de Inteligencia Digital (CENID), University of Alicante (UA)},
  howpublished = {\url{https://huggingface.co/datasets/gplsi/uji_parallel_va_es}} <-- ACTUALIZAR
}
```

## Disclaimer

This resource may contain biases or unintended artifacts.
Any third party using or deploying systems based on this resource is solely responsible for ensuring compliant, safe, and ethical use, including adherence to relevant AI and data protection regulations.

The University of Alicante, as creator and owner of the resource, assumes no liability for outcomes resulting from third-party use.

## License

[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)

